import os
from flask import (
    Flask,
    request,
    render_template,
    redirect,
    url_for,
    session,
    jsonify,
    flash,
)
from flask_socketio import SocketIO, emit, join_room, leave_room, disconnect
import shutil
import threading
import time
from datetime import datetime
import queue
import io
import sys
import builtins
import base64
import bcrypt
import json
import logging

# Supabaseé›†æˆ
try:
    from supabase import create_client, Client
    from dotenv import load_dotenv

    SUPABASE_AVAILABLE = True

    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()

    # Supabaseé…ç½®
    SUPABASE_URL = os.getenv("SUPABASE_URL")
    SUPABASE_KEY = os.getenv("SUPABASE_KEY")

    # åˆå§‹åŒ–Supabaseå®¢æˆ·ç«¯
    supabase: Client = None
    if SUPABASE_URL and SUPABASE_KEY:
        try:
            supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
            print("âœ… Supabaseè¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ Supabaseè¿æ¥å¤±è´¥: {e}")
            print("ğŸ”„ å°†ä½¿ç”¨æœ¬åœ°å­˜å‚¨ä½œä¸ºå¤‡ç”¨")
            SUPABASE_AVAILABLE = False
    else:
        print("âš ï¸ æœªæ‰¾åˆ°Supabaseé…ç½®ï¼Œä½¿ç”¨æœ¬åœ°å­˜å‚¨")
        SUPABASE_AVAILABLE = False

except ImportError as e:
    print(f"âš ï¸ Supabaseåº“æœªå®‰è£…: {e}")
    print("ğŸ”„ å°†ä½¿ç”¨æœ¬åœ°å­˜å‚¨")
    SUPABASE_AVAILABLE = False
    supabase = None

# ä»æ‚¨ç°æœ‰çš„è„šæœ¬å¯¼å…¥è®­ç»ƒå‡½æ•°
# ç¡®ä¿ src ç›®å½•åœ¨ Python è·¯å¾„ä¸­ï¼Œæˆ–è€…è°ƒæ•´å¯¼å…¥æ–¹å¼
sys.path.append(os.path.join(os.path.dirname(__file__), "src"))
from federated_training import train_federated_model
from federated_inference import run_inference

app = Flask(__name__)
app.secret_key = "123456"
socketio = SocketIO(app, cors_allowed_origins="*")

# åœ¨çº¿ç”¨æˆ·è·Ÿè¸ª
online_users = (
    {}
)  # {session_id: {'username': str, 'role': str, 'connected_at': datetime}}
user_sessions = {}  # {username: set of session_ids}

UPLOAD_FOLDER = os.path.join(os.path.dirname(os.path.abspath(__file__)), "uploads")
if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)

# æ¨ç†æ–‡ä»¶ä¸Šä¼ ç›®å½•
INFERENCE_UPLOAD_FOLDER = os.path.join(UPLOAD_FOLDER, "server_inference")
if not os.path.exists(INFERENCE_UPLOAD_FOLDER):
    os.makedirs(INFERENCE_UPLOAD_FOLDER)

# å®¢æˆ·ç«¯æ¨ç†æ–‡ä»¶ä¸Šä¼ ç›®å½•
CLIENT_INFERENCE_UPLOAD_FOLDER = os.path.join(UPLOAD_FOLDER, "client_inference")
if not os.path.exists(CLIENT_INFERENCE_UPLOAD_FOLDER):
    os.makedirs(CLIENT_INFERENCE_UPLOAD_FOLDER)

# æœ¬åœ°ç”¨æˆ·å¤‡ç”¨å­˜å‚¨
LOCAL_USERS_FILE = os.path.join(os.path.dirname(__file__), "local_users.json")

DEFAULT_USERS = {}


def hash_password(password: str) -> str:
    """ä½¿ç”¨bcryptå“ˆå¸Œå¯†ç """
    return bcrypt.hashpw(password.encode("utf-8"), bcrypt.gensalt()).decode("utf-8")


def verify_password(password: str, hashed: str) -> bool:
    """éªŒè¯å¯†ç """
    return bcrypt.checkpw(password.encode("utf-8"), hashed.encode("utf-8"))


def load_local_users():
    """ä»æœ¬åœ°JSONæ–‡ä»¶åŠ è½½ç”¨æˆ·æ•°æ®"""
    try:
        if os.path.exists(LOCAL_USERS_FILE):
            with open(LOCAL_USERS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        else:
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºé»˜è®¤ç”¨æˆ·å¹¶ä¿å­˜
            hashed_users = {}
            for username, data in DEFAULT_USERS.items():
                hashed_users[username] = {
                    "password": hash_password(data["password"]),
                    "role": data["role"],
                    "email": data["email"],
                    "created_at": datetime.now().isoformat(),
                    "is_active": True,
                }
            save_local_users(hashed_users)
            return hashed_users
    except Exception as e:
        print(f"âŒ åŠ è½½æœ¬åœ°ç”¨æˆ·æ•°æ®å¤±è´¥: {e}")
        return {}


def save_local_users(users_data):
    """ä¿å­˜ç”¨æˆ·æ•°æ®åˆ°æœ¬åœ°JSONæ–‡ä»¶"""
    try:
        with open(LOCAL_USERS_FILE, "w", encoding="utf-8") as f:
            json.dump(users_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âŒ ä¿å­˜æœ¬åœ°ç”¨æˆ·æ•°æ®å¤±è´¥: {e}")


def get_user_from_supabase(username: str):
    """ä»Supabaseè·å–ç”¨æˆ·ä¿¡æ¯"""
    if not SUPABASE_AVAILABLE or not supabase:
        return None

    try:
        response = (
            supabase.table("users").select("*").eq("username", username).execute()
        )
        if response.data and len(response.data) > 0:
            return response.data[0]
        return None
    except Exception as e:
        print(f"âŒ ä»Supabaseè·å–ç”¨æˆ·å¤±è´¥: {e}")
        return None


def authenticate_user(username: str, password: str):
    """è®¤è¯ç”¨æˆ· - ä¼˜å…ˆä½¿ç”¨Supabaseï¼Œå¤±è´¥æ—¶ä½¿ç”¨æœ¬åœ°å­˜å‚¨"""

    # é¦–å…ˆå°è¯•Supabaseè®¤è¯
    if SUPABASE_AVAILABLE and supabase:
        try:
            user_data = get_user_from_supabase(username)
            if user_data:
                # éªŒè¯å¯†ç 
                if verify_password(password, user_data["password_hash"]):
                    # æ›´æ–°æœ€åç™»å½•æ—¶é—´
                    try:
                        supabase.table("users").update(
                            {"last_login": datetime.now().isoformat()}
                        ).eq("username", username).execute()
                    except:
                        pass  # å¿½ç•¥æ›´æ–°é”™è¯¯

                    return {
                        "username": user_data["username"],
                        "role": user_data.get("role", "client"),  # ä»æ•°æ®åº“è·å–è§’è‰²
                        "email": user_data.get("email", ""),
                        "source": "supabase",
                    }
                else:
                    print(f"ğŸ” Supabaseå¯†ç éªŒè¯å¤±è´¥: {username}")

        except Exception as e:
            print(f"âš ï¸ Supabaseè®¤è¯å¤±è´¥ï¼Œå°è¯•æœ¬åœ°å­˜å‚¨: {e}")

    # å¤‡ç”¨ï¼šä½¿ç”¨æœ¬åœ°å­˜å‚¨è®¤è¯
    try:
        local_users = load_local_users()
        if username in local_users:
            user_data = local_users[username]
            if verify_password(password, user_data["password"]):
                return {
                    "username": username,
                    "role": user_data["role"],
                    "email": user_data.get("email", ""),
                    "source": "local",
                }

    except Exception as e:
        print(f"âŒ æœ¬åœ°è®¤è¯å¤±è´¥: {e}")

    return None


def create_user_in_supabase(
    username: str, email: str, password: str, role: str = "client"
):
    """åœ¨Supabaseä¸­åˆ›å»ºç”¨æˆ·"""
    if not SUPABASE_AVAILABLE or not supabase:
        return False

    try:
        hashed_password = hash_password(password)
        data = {
            "username": username,
            "email": email,
            "password_hash": hashed_password,
            "role": role,
            "created_at": datetime.now().isoformat(),
            "is_active": True,
        }

        response = supabase.table("users").insert(data).execute()
        return response.data is not None

    except Exception as e:
        print(f"âŒ åœ¨Supabaseåˆ›å»ºç”¨æˆ·å¤±è´¥: {e}")
        return False


def initialize_default_users():
    """åˆå§‹åŒ–é»˜è®¤ç”¨æˆ·åˆ°Supabase"""
    if not SUPABASE_AVAILABLE or not supabase:
        print("ğŸ“ Supabaseä¸å¯ç”¨ï¼Œè·³è¿‡åˆå§‹åŒ–")
        return

    try:
        for username, data in DEFAULT_USERS.items():
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²å­˜åœ¨
            existing = get_user_from_supabase(username)
            if not existing:
                success = create_user_in_supabase(
                    username, data["email"], data["password"], data["role"]
                )
                if success:
                    print(f"âœ… å·²åˆ›å»ºé»˜è®¤ç”¨æˆ·: {username}")
                else:
                    print(f"âŒ åˆ›å»ºé»˜è®¤ç”¨æˆ·å¤±è´¥: {username}")

    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–é»˜è®¤ç”¨æˆ·å¤±è´¥: {e}")


# æ¨¡æ‹Ÿç”¨æˆ·æ•°æ®åº“ - ç°åœ¨ä¸»è¦ç”¨ä½œè§’è‰²æ˜ å°„çš„å¤‡ç”¨
users = DEFAULT_USERS

# å­˜å‚¨å®¢æˆ·ç«¯æ–‡ä»¶ä¸Šä¼ çŠ¶æ€å’Œæ•°æ®è·¯å¾„
# è¿™ä¸ªå˜é‡å°†åœ¨initialize_client_data_status()å‡½æ•°ä¸­åˆå§‹åŒ–
client_data_status = {}

# å…¨å±€è®­ç»ƒçŠ¶æ€å’Œæ—¥å¿—
training_status = {
    "is_training": False,
    "current_round": 0,
    "total_rounds": 0,
    "active_clients": 0,
    "start_time": None,
    "end_time": None,
    "progress": 0,
}

# è®¾ç½®å…¨å±€å˜é‡ï¼Œè®©è®­ç»ƒå‡½æ•°èƒ½å¤Ÿè®¿é—®
builtins.app_training_status = training_status
builtins.socketio = socketio

# å…¨å±€æ¨ç†çŠ¶æ€
inference_status = {
    "is_running": False,
    "progress": 0,
    "current_step": "",
    "result_image": None,
    "error": None,
    "start_time": None,
    "end_time": None,
    "uploaded_files": [],
}

# å®¢æˆ·ç«¯æ¨ç†çŠ¶æ€
client_inference_status = {
    "is_running": False,
    "progress": 0,
    "current_step": "",
    "result_image": None,
    "error": None,
    "start_time": None,
    "end_time": None,
    "uploaded_files": [],
}

# æ—¥å¿—é˜Ÿåˆ—
server_logs = queue.Queue(maxsize=1000)
training_logs = queue.Queue(maxsize=1000)

# æ•°æ®å˜åŒ–è·Ÿè¸ªï¼Œç”¨äºè§¦å‘é¡µé¢åˆ·æ–°
data_change_timestamp = None


def broadcast_user_status():
    """å¹¿æ’­ç”¨æˆ·çŠ¶æ€æ›´æ–°"""
    try:
        # ç»Ÿè®¡åœ¨çº¿ç”¨æˆ·
        online_clients = []
        online_servers = []

        for session_id, user_info in online_users.items():
            if user_info["role"] == "client":
                client_status = client_data_status.get(user_info["username"], {})
                online_clients.append(
                    {
                        "username": user_info["username"],
                        "connected_at": user_info["connected_at"].strftime("%H:%M:%S"),
                        "uploaded": client_status.get("uploaded", False),
                        "file_count": client_status.get("file_count", 0),
                    }
                )
            elif user_info["role"] == "server":
                online_servers.append(
                    {
                        "username": user_info["username"],
                        "connected_at": user_info["connected_at"].strftime("%H:%M:%S"),
                    }
                )

        status_data = {
            "online_clients": online_clients,
            "online_servers": online_servers,
            "total_online": len(online_users),
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        }

        # å¹¿æ’­ç»™æ‰€æœ‰è¿æ¥çš„ç”¨æˆ·
        socketio.emit("user_status_update", status_data)

    except Exception as e:
        print(f"å¹¿æ’­ç”¨æˆ·çŠ¶æ€å¤±è´¥: {e}", file=sys.stderr)


def broadcast_training_status():
    """å¹¿æ’­è®­ç»ƒçŠ¶æ€æ›´æ–°"""
    try:
        socketio.emit("training_status_update", training_status)
    except Exception as e:
        print(f"å¹¿æ’­è®­ç»ƒçŠ¶æ€å¤±è´¥: {e}", file=sys.stderr)


def broadcast_client_data_update():
    """å¹¿æ’­å®¢æˆ·ç«¯æ•°æ®æ›´æ–°"""
    try:
        # è·å–æ‰€æœ‰å®¢æˆ·ç«¯æ•°æ®çŠ¶æ€
        client_info = []
        for uname, uinfo in users.items():
            if uinfo["role"] == "client":
                status = client_data_status.get(uname, {"uploaded": False})
                is_online = uname in user_sessions and len(user_sessions[uname]) > 0

                client_info.append(
                    {
                        "username": uname,
                        "uploaded": status.get("uploaded", False),
                        "file_count": status.get("file_count", 0),
                        "upload_time": status.get("upload_time", "æœªä¸Šä¼ "),
                        "is_online": is_online,
                        "last_login": status.get("last_login", "ä»æœªç™»å½•"),
                    }
                )

        data = {
            "clients": client_info,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        }

        # åªå¹¿æ’­ç»™æœåŠ¡å™¨ç«¯ç”¨æˆ·
        for session_id, user_info in online_users.items():
            if user_info["role"] == "server":
                socketio.emit("client_data_update", data, room=session_id)

    except Exception as e:
        print(f"å¹¿æ’­å®¢æˆ·ç«¯æ•°æ®æ›´æ–°å¤±è´¥: {e}", file=sys.stderr)


def add_server_log(message):
    """æ·»åŠ æœåŠ¡å™¨æ—¥å¿—"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"[{timestamp}] {message}"
    try:
        server_logs.put_nowait(log_entry)
        # å®æ—¶å¹¿æ’­æ—¥å¿—æ›´æ–°
        socketio.emit(
            "logs_update",
            {
                "type": "server",
                "logs": get_logs_list(server_logs),
                "timestamp": timestamp,
            },
        )
    except queue.Full:
        # å¦‚æœé˜Ÿåˆ—æ»¡äº†ï¼Œåˆ é™¤æœ€æ—§çš„æ—¥å¿—
        try:
            server_logs.get_nowait()
            server_logs.put_nowait(log_entry)
        except queue.Empty:
            pass
    except Exception as e:
        print(f"æ·»åŠ æœåŠ¡å™¨æ—¥å¿—å¤±è´¥: {e}", file=sys.stderr)


def add_training_log(message):
    """æ·»åŠ è®­ç»ƒæ—¥å¿—"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"[{timestamp}] {message}"
    try:
        training_logs.put_nowait(log_entry)
        # å®æ—¶å¹¿æ’­æ—¥å¿—æ›´æ–°
        socketio.emit(
            "logs_update",
            {
                "type": "training",
                "logs": get_logs_list(training_logs),
                "timestamp": timestamp,
            },
        )
    except queue.Full:
        # å¦‚æœé˜Ÿåˆ—æ»¡äº†ï¼Œåˆ é™¤æœ€æ—§çš„æ—¥å¿—
        try:
            training_logs.get_nowait()
            training_logs.put_nowait(log_entry)
        except queue.Empty:
            pass


# è®¾ç½®æ—¥å¿—å‡½æ•°ä¸ºå…¨å±€å¯è®¿é—®
builtins.add_server_log = add_server_log
builtins.add_training_log = add_training_log


def get_logs_list(log_queue):
    """è·å–æ—¥å¿—åˆ—è¡¨"""
    logs = []
    temp_logs = []

    # å–å‡ºæ‰€æœ‰æ—¥å¿—
    while not log_queue.empty():
        try:
            log = log_queue.get_nowait()
            temp_logs.append(log)
        except queue.Empty:
            break

    # ä¿ç•™æœ€æ–°çš„100æ¡æ—¥å¿—
    recent_logs = temp_logs[-100:] if len(temp_logs) > 100 else temp_logs

    # é‡æ–°æ”¾å›é˜Ÿåˆ—
    for log in recent_logs:
        try:
            log_queue.put_nowait(log)
        except queue.Full:
            break

    return recent_logs


# WebSocket äº‹ä»¶å¤„ç†
@socketio.on("connect")
def handle_connect():
    """ç”¨æˆ·è¿æ¥äº‹ä»¶"""
    if "username" not in session:
        disconnect()
        return False

    username = session["username"]
    role = session["role"]
    session_id = request.sid

    # è®°å½•ç”¨æˆ·åœ¨çº¿çŠ¶æ€
    online_users[session_id] = {
        "username": username,
        "role": role,
        "connected_at": datetime.now(),
    }

    # ç»´æŠ¤ç”¨æˆ·ä¼šè¯æ˜ å°„
    if username not in user_sessions:
        user_sessions[username] = set()
    user_sessions[username].add(session_id)

    # åŠ å…¥å¯¹åº”çš„æˆ¿é—´
    join_room(f"{role}_room")
    join_room(f"user_{username}")

    add_server_log(f"ç”¨æˆ· {username} ({role}) å»ºç«‹ WebSocket è¿æ¥")

    # å¹¿æ’­ç”¨æˆ·çŠ¶æ€æ›´æ–°
    broadcast_user_status()

    # å¦‚æœæ˜¯æœåŠ¡å™¨ç”¨æˆ·ï¼Œå‘é€å®¢æˆ·ç«¯æ•°æ®
    if role == "server":
        broadcast_client_data_update()

    return True


@socketio.on("disconnect")
def handle_disconnect():
    """ç”¨æˆ·æ–­å¼€è¿æ¥äº‹ä»¶"""
    session_id = request.sid

    if session_id in online_users:
        user_info = online_users[session_id]
        username = user_info["username"]
        role = user_info["role"]

        # æ¸…ç†åœ¨çº¿çŠ¶æ€
        del online_users[session_id]

        if username in user_sessions:
            user_sessions[username].discard(session_id)
            if not user_sessions[username]:  # å¦‚æœç”¨æˆ·æ²¡æœ‰å…¶ä»–è¿æ¥
                del user_sessions[username]

        add_server_log(f"ç”¨æˆ· {username} ({role}) æ–­å¼€ WebSocket è¿æ¥")

        # å¹¿æ’­ç”¨æˆ·çŠ¶æ€æ›´æ–°
        broadcast_user_status()


@socketio.on("request_status_update")
def handle_status_request():
    """å¤„ç†çŠ¶æ€æ›´æ–°è¯·æ±‚"""
    if "username" not in session:
        return

    role = session["role"]

    # å‘é€ç”¨æˆ·çŠ¶æ€
    broadcast_user_status()

    # å¦‚æœæ˜¯æœåŠ¡å™¨ç”¨æˆ·ï¼Œè¿˜è¦å‘é€å®¢æˆ·ç«¯æ•°æ®å’Œè®­ç»ƒçŠ¶æ€
    if role == "server":
        broadcast_client_data_update()
        broadcast_training_status()


@socketio.on("heartbeat")
def handle_heartbeat():
    """å¿ƒè·³æ£€æµ‹"""
    emit("heartbeat_response", {"timestamp": datetime.now().isoformat()})


@socketio.on("request_logs")
def handle_logs_request(data):
    """å¤„ç†æ—¥å¿—è¯·æ±‚"""
    if "username" not in session or session["role"] != "server":
        return

    log_type = data.get("type", "server")

    if log_type == "server":
        logs = get_logs_list(server_logs)
    elif log_type == "training":
        logs = get_logs_list(training_logs)
    else:
        logs = []

    emit(
        "logs_update",
        {
            "type": log_type,
            "logs": logs,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        },
    )


# WebSocket handlers for training data
@socketio.on("join_training_room")
def handle_join_training_room(data):
    """å®¢æˆ·ç«¯åŠ å…¥è®­ç»ƒç›‘æ§æˆ¿é—´"""
    if "username" not in session:
        return

    username = session["username"]
    role = session["role"]
    client_id = data.get("client_id", username)

    print(f"ç”¨æˆ· {username} (è§’è‰²: {role}) åŠ å…¥è®­ç»ƒç›‘æ§æˆ¿é—´ï¼Œå®¢æˆ·ç«¯ID: {client_id}")

    # åŠ å…¥å¯¹åº”çš„è®­ç»ƒç›‘æ§æˆ¿é—´
    if role == "client":
        # å®¢æˆ·ç«¯åŠ å…¥ç‰¹å®šçš„è®­ç»ƒç›‘æ§æˆ¿é—´
        join_room(f"client_{client_id}_training")
        join_room("server_training")  # ä¹ŸåŠ å…¥æœåŠ¡å™¨æˆ¿é—´æ¥æ”¶æ€»ä½“æ•°æ®
    elif role == "server":
        join_room("server_training")

    emit(
        "training_room_joined",
        {"status": "success", "room": f"{role}_training", "client_id": client_id},
    )


@socketio.on("request_training_data")
def handle_training_data_request(data):
    """å¤„ç†è®­ç»ƒæ•°æ®è¯·æ±‚"""
    if "username" not in session:
        return

    username = session["username"]
    role = session["role"]
    client_id = data.get("client_id", username)

    # è¿”å›è¯·æ±‚çš„è®­ç»ƒæ•°æ®ï¼ˆè¿™é‡Œå¯ä»¥ä»å­˜å‚¨ä¸­è·å–å†å²æ•°æ®ï¼‰
    emit(
        "training_data_response",
        {
            "client_id": client_id,
            "data": [],  # è¿™é‡Œå¯ä»¥æ·»åŠ å†å²æ•°æ®è·å–é€»è¾‘
            "timestamp": datetime.now().isoformat(),
        },
    )


# REST API endpoints for training data
@app.route("/api/training/client/<client_id>/data", methods=["GET"])
def get_client_training_data(client_id):
    """è·å–ç‰¹å®šå®¢æˆ·ç«¯çš„è®­ç»ƒæ•°æ®"""
    if "username" not in session or session["role"] not in ["server", "client"]:
        return jsonify({"error": "æœªæˆæƒ"}), 401

    # å¦‚æœæ˜¯å®¢æˆ·ç«¯ï¼Œåªèƒ½è®¿é—®è‡ªå·±çš„æ•°æ®
    if session["role"] == "client" and session["username"] != client_id:
        return jsonify({"error": "æƒé™ä¸è¶³"}), 403

    # è¿™é‡Œå¯ä»¥ä»æ•°æ®åº“æˆ–æ–‡ä»¶ç³»ç»Ÿè·å–è®­ç»ƒæ•°æ®
    # ç›®å‰è¿”å›ç©ºæ•°æ®ï¼Œå®é™…å®ç°æ—¶å¯ä»¥æ·»åŠ æ•°æ®æŒä¹…åŒ–
    return jsonify(
        {
            "client_id": client_id,
            "training_data": [],
            "timestamp": datetime.now().isoformat(),
        }
    )


@app.route("/api/training/server/data", methods=["GET"])
def get_server_training_data():
    """è·å–æœåŠ¡å™¨ç«¯è®­ç»ƒæ•°æ®"""
    if "username" not in session or session["role"] != "server":
        return jsonify({"error": "æœªæˆæƒ"}), 401

    # è¿”å›æœåŠ¡å™¨ç«¯èšåˆè®­ç»ƒæ•°æ®
    return jsonify(
        {
            "server_data": [],
            "all_clients_data": {},
            "timestamp": datetime.now().isoformat(),
        }
    )


@app.route("/", methods=["GET", "POST"])
def login():
    if request.method == "POST":
        username = request.form["username"]
        password = request.form["password"]

        # ä½¿ç”¨supabaseè®¤è¯
        auth_result = authenticate_user(username, password)

        if auth_result:
            session["username"] = username
            session["role"] = auth_result["role"]
            session["email"] = auth_result.get("email", "")
            session["auth_source"] = auth_result["source"]

            add_server_log(
                f"ç”¨æˆ· {username} ({auth_result['role']}) ç™»å½•æˆåŠŸ [æ¥æº: {auth_result['source']}]"
            )

            if auth_result["role"] == "server":
                return redirect(url_for("server_dashboard"))
            else:
                # åˆå§‹åŒ–å®¢æˆ·ç«¯æ•°æ®çŠ¶æ€ï¼ˆå¦‚æœå°šä¸å­˜åœ¨ï¼‰
                if username not in client_data_status:
                    client_data_status[username] = {
                        "uploaded": False,
                        "data_path": None,
                        "last_login": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    }
                else:
                    client_data_status[username][
                        "last_login"
                    ] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                return redirect(url_for("client_dashboard"))

        add_server_log(f"ç”¨æˆ· {username} ç™»å½•å¤±è´¥ - æ— æ•ˆå‡­æ®")
        # å¯¹äºAJAXè¯·æ±‚ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
        if (
            request.is_json
            or request.headers.get("Content-Type")
            == "application/x-www-form-urlencoded"
        ):
            return "æ— æ•ˆçš„å‡­æ®", 400
        return redirect(url_for("login", error="1"))
    return render_template("login.html")


@app.route("/logout")
def logout():
    username = session.get("username", "æœªçŸ¥ç”¨æˆ·")
    add_server_log(f"ç”¨æˆ· {username} ç™»å‡º")
    session.pop("username", None)
    session.pop("role", None)
    return redirect(url_for("login"))


@app.route("/register", methods=["GET", "POST"])
def register():
    if request.method == "POST":
        username = request.form.get("username", "").strip()
        email = request.form.get("email", "").strip()
        password = request.form.get("password", "")
        confirm_password = request.form.get("confirm_password", "")

        # åŸºæœ¬éªŒè¯
        if not username or not email or not password:
            flash("æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¿…å¡«çš„", "error")
            return render_template("register.html")

        if len(username) < 3:
            flash("ç”¨æˆ·åè‡³å°‘éœ€è¦3ä¸ªå­—ç¬¦", "error")
            return render_template("register.html")

        if len(password) < 6:
            flash("å¯†ç è‡³å°‘éœ€è¦6ä¸ªå­—ç¬¦", "error")
            return render_template("register.html")

        if password != confirm_password:
            flash("å¯†ç ä¸åŒ¹é…", "error")
            return render_template("register.html")

        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²å­˜åœ¨
        if SUPABASE_AVAILABLE and supabase:
            existing_user = get_user_from_supabase(username)
            if existing_user:
                flash("ç”¨æˆ·åå·²å­˜åœ¨", "error")
                return render_template("register.html")
        else:
            # æ£€æŸ¥æœ¬åœ°ç”¨æˆ·
            local_users = load_local_users()
            if username in local_users:
                flash("ç”¨æˆ·åå·²å­˜åœ¨", "error")
                return render_template("register.html")

        # åˆ›å»ºç”¨æˆ·
        success = False

        # ä¼˜å…ˆå°è¯•Supabase
        if SUPABASE_AVAILABLE and supabase:
            success = create_user_in_supabase(
                username, email, password, "client"
            )  # æ–°æ³¨å†Œç”¨æˆ·é»˜è®¤ä¸ºå®¢æˆ·ç«¯
            if success:
                add_server_log(f"æ–°ç”¨æˆ· {username} æ³¨å†ŒæˆåŠŸ [Supabase]")
                flash("æ³¨å†ŒæˆåŠŸï¼è¯·ç™»å½•", "success")
            else:
                flash("æ³¨å†Œå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•", "error")

        # å¤‡ç”¨ï¼šæœ¬åœ°å­˜å‚¨
        if not success:
            try:
                local_users = load_local_users()
                local_users[username] = {
                    "password": hash_password(password),
                    "role": "client",  # æ–°æ³¨å†Œç”¨æˆ·é»˜è®¤ä¸ºå®¢æˆ·ç«¯
                    "email": email,
                    "created_at": datetime.now().isoformat(),
                    "is_active": True,
                }
                save_local_users(local_users)
                add_server_log(f"æ–°ç”¨æˆ· {username} æ³¨å†ŒæˆåŠŸ [æœ¬åœ°å­˜å‚¨]")
                flash("æ³¨å†ŒæˆåŠŸï¼è¯·ç™»å½•", "success")
                success = True
            except Exception as e:
                print(f"âŒ æœ¬åœ°æ³¨å†Œå¤±è´¥: {e}")
                flash("æ³¨å†Œå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•", "error")

        if success:
            return redirect(url_for("login"))

    return render_template("register.html")


@app.route("/client/dashboard", methods=["GET"])
def client_dashboard():
    if "username" not in session or session["role"] != "client":
        return redirect(url_for("login"))

    status = client_data_status.get(
        session["username"], {"uploaded": False, "data_path": None}
    )
    return render_template(
        "client_dashboard.html", username=session["username"], status=status
    )  # æ‚¨éœ€è¦åˆ›å»ºæ­¤HTMLæ–‡ä»¶


@app.route("/client/upload", methods=["POST"])
def upload_file():
    if "username" not in session or session["role"] != "client":
        return jsonify({"error": "æœªæˆæƒ"}), 403

    username = session["username"]

    # æ”¯æŒå¤šæ–‡ä»¶ä¸Šä¼  - æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶
    uploaded_files = request.files.getlist("files")
    if not uploaded_files or len(uploaded_files) == 0:
        return jsonify({"error": "æœªé€‰æ‹©æ–‡ä»¶"}), 400

    client_folder_name = f"{username}_data"
    client_upload_path = os.path.join(UPLOAD_FOLDER, client_folder_name)

    if not os.path.exists(client_upload_path):
        os.makedirs(client_upload_path)

    uploaded_count = 0
    mhd_count = 0
    raw_count = 0
    uploaded_filenames = []

    # å¤„ç†æ¯ä¸ªä¸Šä¼ çš„æ–‡ä»¶
    for file in uploaded_files:
        if file.filename == "":
            continue

        filename = file.filename
        file_path = os.path.join(client_upload_path, filename)

        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œç”Ÿæˆæ–°çš„æ–‡ä»¶å
        counter = 1
        base_name, ext = os.path.splitext(filename)
        while os.path.exists(file_path):
            new_filename = f"{base_name}_{counter}{ext}"
            file_path = os.path.join(client_upload_path, new_filename)
            filename = new_filename
            counter += 1

        file.save(file_path)
        uploaded_filenames.append(filename)
        uploaded_count += 1

        # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
        if filename.lower().endswith(".mhd"):
            mhd_count += 1
        elif filename.lower().endswith(".raw"):
            raw_count += 1

    if uploaded_count == 0:
        return jsonify({"error": "æ²¡æœ‰æˆåŠŸä¸Šä¼ æ–‡ä»¶"}), 400

    # è®¡ç®—æ€»æ–‡ä»¶æ•°ï¼ˆåŒ…æ‹¬ä¹‹å‰ä¸Šä¼ çš„ï¼‰
    all_files = os.listdir(client_upload_path)
    total_mhd = len([f for f in all_files if f.lower().endswith(".mhd")])
    total_raw = len([f for f in all_files if f.lower().endswith(".raw")])
    # åªè®¡ç®—æœ‰æ•ˆçš„åŒ»å­¦å½±åƒæ–‡ä»¶ï¼ˆ.mhdå’Œ.rawï¼‰
    total_files = total_mhd + total_raw

    # æ›´æ–°å®¢æˆ·ç«¯çŠ¶æ€
    client_data_status[username] = {
        "uploaded": True,
        "data_path": client_upload_path,
        "upload_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "file_count": total_files,
        "mhd_count": total_mhd,
        "raw_count": total_raw,
        "file_pairs": min(total_mhd, total_raw),  # æœ‰æ•ˆçš„æ–‡ä»¶å¯¹æ•°
        "last_login": client_data_status.get(username, {}).get("last_login", "æœªçŸ¥"),
    }

    add_server_log(
        f"å®¢æˆ·ç«¯ {username} ä¸Šä¼  {uploaded_count} ä¸ªæ–‡ä»¶: {', '.join(uploaded_filenames[:3])}{('...' if len(uploaded_filenames) > 3 else '')}"
    )

    # æ›´æ–°æ•°æ®å˜åŒ–æ—¶é—´æˆ³ï¼Œç”¨äºè§¦å‘é¡µé¢åˆ·æ–°
    global data_change_timestamp
    data_change_timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # å®æ—¶å¹¿æ’­å®¢æˆ·ç«¯æ•°æ®æ›´æ–°
    broadcast_client_data_update()
    broadcast_user_status()

    return jsonify(
        {
            "message": f"æˆåŠŸä¸Šä¼  {uploaded_count} ä¸ªæ–‡ä»¶",
            "data_path": client_upload_path,
            "uploaded_files": uploaded_filenames,
            "total_files": total_files,
            "mhd_count": total_mhd,
            "raw_count": total_raw,
            "file_pairs": min(total_mhd, total_raw),
        }
    )


@app.route("/server/dashboard", methods=["GET"])
def server_dashboard():
    if "username" not in session or session["role"] != "server":
        return redirect(url_for("login"))

    # è·å–æ‰€æœ‰å®¢æˆ·ç«¯ç”¨æˆ·ä¿¡æ¯
    active_clients_info = []

    # ä¼˜å…ˆä»Supabaseè·å–ç”¨æˆ·åˆ—è¡¨
    if SUPABASE_AVAILABLE and supabase:
        try:
            response = supabase.table("users").select("*").execute()
            if response.data:
                for user_data in response.data:
                    if user_data["username"] != "server":  # æ’é™¤æœåŠ¡å™¨ç”¨æˆ·
                        status = client_data_status.get(
                            user_data["username"],
                            {
                                "uploaded": False,
                                "data_path": None,
                                "last_login": "ä»æœªç™»å½•",
                                "upload_time": "ä»æœªä¸Šä¼ ",
                                "file_count": 0,
                            },
                        )
                        active_clients_info.append(
                            {
                                "username": user_data["username"],
                                "logged_in": True,  # ç®€åŒ–ï¼šå‡è®¾å¦‚æœå­˜åœ¨äºæ•°æ®åº“å°±å¯èƒ½ç™»å½•
                                "file_uploaded": status["uploaded"],
                                "last_login": status.get("last_login", "ä»æœªç™»å½•"),
                                "upload_time": status.get("upload_time", "ä»æœªä¸Šä¼ "),
                                "file_count": status.get("file_count", 0),
                                "data_path": status.get("data_path", "æ— "),
                            }
                        )
        except Exception as e:
            print(f"âš ï¸ ä»Supabaseè·å–ç”¨æˆ·åˆ—è¡¨å¤±è´¥: {e}")

    # å¤‡ç”¨ï¼šä»æœ¬åœ°ç”¨æˆ·æ•°æ®è·å–
    if not active_clients_info:  # å¦‚æœSupabaseè·å–å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ•°æ®
        try:
            local_users = load_local_users()
            for uname, uinfo in local_users.items():
                if uinfo.get("role") == "client":
                    status = client_data_status.get(
                        uname,
                        {
                            "uploaded": False,
                            "data_path": None,
                            "last_login": "ä»æœªç™»å½•",
                            "upload_time": "ä»æœªä¸Šä¼ ",
                            "file_count": 0,
                        },
                    )
                    active_clients_info.append(
                        {
                            "username": uname,
                            "logged_in": True,  # ç®€åŒ–ï¼šå‡è®¾å¦‚æœå­˜åœ¨äºæœ¬åœ°ç”¨æˆ·å°±å¯èƒ½ç™»å½•
                            "file_uploaded": status["uploaded"],
                            "last_login": status.get("last_login", "ä»æœªç™»å½•"),
                            "upload_time": status.get("upload_time", "ä»æœªä¸Šä¼ "),
                            "file_count": status.get("file_count", 0),
                            "data_path": status.get("data_path", "æ— "),
                        }
                    )
        except Exception as e:
            print(f"âŒ ä»æœ¬åœ°è·å–ç”¨æˆ·åˆ—è¡¨å¤±è´¥: {e}")

    # æœ€åçš„å¤‡ç”¨ï¼šä½¿ç”¨é»˜è®¤ç”¨æˆ·ï¼ˆåªæœ‰åœ¨å‰é¢éƒ½å¤±è´¥æ—¶ï¼‰
    if not active_clients_info:
        for uname, uinfo in DEFAULT_USERS.items():
            if uinfo["role"] == "client":
                status = client_data_status.get(
                    uname,
                    {
                        "uploaded": False,
                        "data_path": None,
                        "last_login": "ä»æœªç™»å½•",
                        "upload_time": "ä»æœªä¸Šä¼ ",
                        "file_count": 0,
                    },
                )
                active_clients_info.append(
                    {
                        "username": uname,
                        "logged_in": True,  # ç®€åŒ–ï¼šå‡è®¾å¦‚æœå­˜åœ¨äºé»˜è®¤ç”¨æˆ·å°±å¯èƒ½ç™»å½•
                        "file_uploaded": status["uploaded"],
                        "last_login": status.get("last_login", "ä»æœªç™»å½•"),
                        "upload_time": status.get("upload_time", "ä»æœªä¸Šä¼ "),
                        "file_count": status.get("file_count", 0),
                        "data_path": status.get("data_path", "æ— "),
                    }
                )

    return render_template(
        "server_dashboard.html",
        clients=active_clients_info,
        training_status=training_status,
    )  # æ‚¨éœ€è¦åˆ›å»ºæ­¤HTMLæ–‡ä»¶


@app.route("/server/start_training", methods=["POST"])
def start_training():
    if "username" not in session or session["role"] != "server":
        return jsonify({"error": "æœªæˆæƒ"}), 403

    if training_status["is_training"]:
        return jsonify({"error": "è®­ç»ƒæ­£åœ¨è¿›è¡Œä¸­"}), 400

    # è·å–è®­ç»ƒå‚æ•°ï¼ˆä»è¯·æ±‚ä¸­ï¼‰
    data = request.get_json() if request.is_json else {}
    global_rounds = data.get("global_rounds", 5)  # é»˜è®¤5è½®
    local_epochs = data.get("local_epochs", 2)  # é»˜è®¤2ä¸ªæœ¬åœ°epochs

    # å‚æ•°éªŒè¯
    global_rounds = max(1, min(20, int(global_rounds)))  # é™åˆ¶åœ¨1-20ä¹‹é—´
    local_epochs = max(1, min(10, int(local_epochs)))  # é™åˆ¶åœ¨1-10ä¹‹é—´

    client_paths_for_training = []
    for client_name, status in client_data_status.items():
        if status.get("uploaded") and status.get("data_path"):
            client_paths_for_training.append(status["data_path"])

    if not client_paths_for_training:
        add_server_log("è®­ç»ƒå¯åŠ¨å¤±è´¥ - æ²¡æœ‰å®¢æˆ·ç«¯ä¸Šä¼ æ•°æ®")
        return jsonify({"error": "æ²¡æœ‰å®¢æˆ·ç«¯ä¸Šä¼ æ•°æ®ç”¨äºè®­ç»ƒ"}), 400

    num_active_clients = len(client_paths_for_training)

    # æ›´æ–°è®­ç»ƒçŠ¶æ€
    training_status.update(
        {
            "is_training": True,
            "current_round": 0,
            "total_rounds": global_rounds,
            "active_clients": num_active_clients,
            "start_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "end_time": None,
            "progress": 0,
        }
    )

    add_server_log(
        f"å¼€å§‹è”é‚¦å­¦ä¹ è®­ç»ƒ - {num_active_clients} ä¸ªå®¢æˆ·ç«¯å‚ä¸ (å…¨å±€è½®æ•°: {global_rounds}, æœ¬åœ°è½®æ•°: {local_epochs})"
    )
    add_training_log(f"è®­ç»ƒåˆå§‹åŒ– - å®¢æˆ·ç«¯æ•°æ®ç›®å½•: {client_paths_for_training}")

    def run_training():
        try:
            add_training_log("æ­£åœ¨å¯åŠ¨è”é‚¦å­¦ä¹ è®­ç»ƒ...")
            add_training_log(f"å‚ä¸è®­ç»ƒçš„å®¢æˆ·ç«¯æ•°é‡: {num_active_clients}")
            add_training_log(f"å…¨å±€è®­ç»ƒè½®æ•°: {global_rounds}")
            add_training_log(f"æœ¬åœ°è®­ç»ƒè½®æ•°: {local_epochs}")
            add_training_log(f"å®¢æˆ·ç«¯æ•°æ®è·¯å¾„: {client_paths_for_training}")

            add_training_log("è®­ç»ƒæ—¥å¿—ç³»ç»Ÿå·²åˆå§‹åŒ–")

            coordinator = train_federated_model(
                num_clients=num_active_clients,
                global_rounds=global_rounds,
                local_epochs=local_epochs,
                client_data_dirs=client_paths_for_training,
            )

            # æ›´æ–°è®­ç»ƒçŠ¶æ€
            training_status.update(
                {
                    "is_training": False,
                    "current_round": global_rounds,
                    "end_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "progress": 100,
                }
            )

            if coordinator:
                add_server_log("è”é‚¦å­¦ä¹ è®­ç»ƒæˆåŠŸå®Œæˆ")
                add_training_log("è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜")
            else:
                add_server_log("è”é‚¦å­¦ä¹ è®­ç»ƒå¤±è´¥")
                add_training_log("è®­ç»ƒå¤±è´¥ - åè°ƒå™¨æœªæˆåŠŸåˆå§‹åŒ–")

        except Exception as e:
            training_status.update(
                {
                    "is_training": False,
                    "end_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                }
            )
            add_server_log(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            add_training_log(f"è®­ç»ƒå¼‚å¸¸ç»ˆæ­¢: {str(e)}")
        finally:
            # æ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½å¹¿æ’­è®­ç»ƒçŠ¶æ€æ›´æ–°
            broadcast_training_status()

    # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œè®­ç»ƒ
    training_thread = threading.Thread(target=run_training)
    training_thread.daemon = True
    training_thread.start()

    # å¹¿æ’­è®­ç»ƒå¼€å§‹çŠ¶æ€
    broadcast_training_status()

    return jsonify({"message": "è®­ç»ƒå·²å¯åŠ¨ï¼Œè¯·æŸ¥çœ‹è®­ç»ƒæ—¥å¿—è·å–è¿›åº¦"})


@app.route("/api/server/status", methods=["GET"])
def get_server_status():
    """è·å–æœåŠ¡å™¨çŠ¶æ€API"""
    if "username" not in session or session["role"] != "server":
        return jsonify({"error": "æœªæˆæƒ"}), 403

    client_count = len([c for c in client_data_status.values() if c.get("uploaded")])
    total_clients = len([u for u, info in users.items() if info["role"] == "client"])

    response_data = {
        "training_status": training_status,
        "client_count": client_count,
        "total_clients": total_clients,
        "server_logs": get_logs_list(server_logs),
        "training_logs": get_logs_list(training_logs),
        "data_change_timestamp": data_change_timestamp,
    }

    return jsonify(response_data)


@app.route("/api/server/logs", methods=["GET"])
def get_logs():
    """è·å–æ—¥å¿—API"""
    if "username" not in session or session["role"] != "server":
        return jsonify({"error": "æœªæˆæƒ"}), 403

    log_type = request.args.get("type", "server")

    if log_type == "training":
        logs = get_logs_list(training_logs)
    else:
        logs = get_logs_list(server_logs)

    return jsonify({"logs": logs})


# è‡ªåŠ¨æ£€æµ‹å’Œåˆå§‹åŒ–å®¢æˆ·ç«¯æ•°æ®çŠ¶æ€
def initialize_client_data_status():
    """è‡ªåŠ¨æ£€æµ‹uploadsç›®å½•ä¸­çš„å®¢æˆ·ç«¯æ•°æ®å¹¶åˆå§‹åŒ–çŠ¶æ€"""
    global client_data_status

    print("æ­£åœ¨æ£€æµ‹å®¢æˆ·ç«¯æ•°æ®...")

    for username in users:
        if users[username]["role"] == "client":
            client_data_dir = os.path.join(UPLOAD_FOLDER, f"{username}_data")

            # æ£€æŸ¥å®¢æˆ·ç«¯æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
            if os.path.exists(client_data_dir):
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ•°æ®æ–‡ä»¶
                files = os.listdir(client_data_dir)
                mhd_files = [f for f in files if f.endswith(".mhd")]
                raw_files = [f for f in files if f.endswith(".raw")]

                if mhd_files and raw_files:
                    client_data_status[username] = {
                        "uploaded": True,
                        "data_path": client_data_dir,
                        "last_login": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "file_count": len(mhd_files),
                    }
                    print(f"âœ… æ£€æµ‹åˆ° {username} çš„æ•°æ®: {len(mhd_files)} ä¸ªæ–‡ä»¶")
                else:
                    print(f"âš ï¸ {username} çš„æ•°æ®ç›®å½•å­˜åœ¨ä½†æ— æœ‰æ•ˆæ•°æ®æ–‡ä»¶")
            else:
                print(f"âŒ {username} çš„æ•°æ®ç›®å½•ä¸å­˜åœ¨: {client_data_dir}")


# æ¨ç†ç›¸å…³APIç«¯ç‚¹
@app.route("/api/server/upload_inference_file", methods=["POST"])
def upload_inference_file():
    """ä¸Šä¼ æ¨ç†æ–‡ä»¶ï¼ˆæ”¯æŒå¤šæ–‡ä»¶ä¸Šä¼ ï¼‰"""
    if "username" not in session or session["role"] != "server":
        return jsonify({"error": "æœªæˆæƒ"}), 403

    files = request.files.getlist("files")
    if not files or len(files) == 0:
        return jsonify({"error": "æœªé€‰æ‹©æ–‡ä»¶"}), 400

    uploaded_files = []
    errors = []

    # éªŒè¯æ–‡ä»¶ç±»å‹å’Œé…å¯¹
    mhd_files = []
    raw_files = []

    for file in files:
        if file.filename == "":
            continue

        if file.filename.lower().endswith(".mhd"):
            mhd_files.append(file)
        elif file.filename.lower().endswith(".raw"):
            raw_files.append(file)
        else:
            errors.append(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file.filename}")

    if not mhd_files:
        return jsonify({"error": "å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ª.mhdæ–‡ä»¶"}), 400

    # éªŒè¯æ¯ä¸ª.mhdæ–‡ä»¶éƒ½æœ‰å¯¹åº”çš„.rawæ–‡ä»¶
    for mhd_file in mhd_files:
        base_name = os.path.splitext(mhd_file.filename)[0]
        raw_filename = base_name + ".raw"

        # æŸ¥æ‰¾å¯¹åº”çš„.rawæ–‡ä»¶
        corresponding_raw = None
        for raw_file in raw_files:
            if raw_file.filename == raw_filename:
                corresponding_raw = raw_file
                break

        if not corresponding_raw:
            errors.append(f"ç¼ºå°‘å¯¹åº”çš„.rawæ–‡ä»¶: {raw_filename}")
            continue

        # ä¸Šä¼ æ–‡ä»¶å¯¹
        try:
            # å¤„ç†æ–‡ä»¶åå†²çª
            mhd_filename = mhd_file.filename
            raw_filename = corresponding_raw.filename

            counter = 1
            base_name = os.path.splitext(mhd_filename)[0]

            while os.path.exists(
                os.path.join(INFERENCE_UPLOAD_FOLDER, mhd_filename)
            ) or os.path.exists(os.path.join(INFERENCE_UPLOAD_FOLDER, raw_filename)):
                mhd_filename = f"{base_name}_{counter}.mhd"
                raw_filename = f"{base_name}_{counter}.raw"
                counter += 1

            # ä¿å­˜.mhdæ–‡ä»¶
            mhd_path = os.path.join(INFERENCE_UPLOAD_FOLDER, mhd_filename)
            mhd_file.save(mhd_path)

            # ä¿å­˜.rawæ–‡ä»¶
            raw_path = os.path.join(INFERENCE_UPLOAD_FOLDER, raw_filename)
            corresponding_raw.save(raw_path)

            # åªå°†.mhdæ–‡ä»¶æ·»åŠ åˆ°çŠ¶æ€ä¸­ï¼ˆæ¨ç†æ—¶ä½¿ç”¨ï¼‰
            inference_status["uploaded_files"].append(
                {
                    "name": mhd_filename,
                    "path": mhd_path,
                    "raw_file": raw_filename,
                    "upload_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                }
            )

            uploaded_files.extend([mhd_filename, raw_filename])
            add_server_log(f"æ¨ç†æ–‡ä»¶å¯¹ä¸Šä¼ æˆåŠŸ: {mhd_filename}, {raw_filename}")

        except Exception as e:
            errors.append(f"ä¸Šä¼ æ–‡ä»¶å¯¹å¤±è´¥ {mhd_file.filename}: {str(e)}")

    if not uploaded_files and errors:
        return jsonify({"error": f"ä¸Šä¼ å¤±è´¥: {'; '.join(errors)}"}), 500

    response_message = f"æˆåŠŸä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶"
    if errors:
        response_message += f" (éƒ¨åˆ†é”™è¯¯: {'; '.join(errors)})"

    return jsonify(
        {
            "message": response_message,
            "uploaded_files": uploaded_files,
            "errors": errors,
        }
    )


@app.route("/api/server/list_inference_files", methods=["GET"])
def list_inference_files():
    """è·å–å·²ä¸Šä¼ çš„æ¨ç†æ–‡ä»¶åˆ—è¡¨"""
    if "username" not in session or session["role"] != "server":
        return jsonify({"error": "æœªæˆæƒ"}), 403

    files = []
    if os.path.exists(INFERENCE_UPLOAD_FOLDER):
        for filename in os.listdir(INFERENCE_UPLOAD_FOLDER):
            if filename.lower().endswith(".mhd"):
                file_path = os.path.join(INFERENCE_UPLOAD_FOLDER, filename)
                stat = os.stat(file_path)

                # æ£€æŸ¥å¯¹åº”çš„.rawæ–‡ä»¶æ˜¯å¦å­˜åœ¨
                base_name = os.path.splitext(filename)[0]
                raw_filename = base_name + ".raw"
                raw_path = os.path.join(INFERENCE_UPLOAD_FOLDER, raw_filename)
                has_raw_file = os.path.exists(raw_path)

                raw_size = 0
                if has_raw_file:
                    raw_stat = os.stat(raw_path)
                    raw_size = raw_stat.st_size

                files.append(
                    {
                        "name": filename,
                        "path": file_path,
                        "size": stat.st_size,
                        "raw_file": raw_filename if has_raw_file else None,
                        "raw_size": raw_size,
                        "total_size": stat.st_size + raw_size,
                        "has_pair": has_raw_file,
                        "upload_time": datetime.fromtimestamp(stat.st_mtime).strftime(
                            "%Y-%m-%d %H:%M:%S"
                        ),
                    }
                )

    return jsonify({"files": files})


@app.route("/api/server/run_inference", methods=["POST"])
def run_inference_api():
    """è¿è¡Œæ¨ç†"""
    if "username" not in session or session["role"] != "server":
        return jsonify({"error": "æœªæˆæƒ"}), 403

    if inference_status["is_running"]:
        return jsonify({"error": "æ¨ç†æ­£åœ¨è¿è¡Œä¸­"}), 400

    data = request.get_json()
    filename = data.get("filename")
    use_federated = data.get("use_federated", True)
    fast_mode = data.get("fast_mode", False)

    if not filename:
        return jsonify({"error": "æœªæŒ‡å®šæ–‡ä»¶å"}), 400

    file_path = os.path.join(INFERENCE_UPLOAD_FOLDER, filename)
    if not os.path.exists(file_path):
        return jsonify({"error": "MHDæ–‡ä»¶ä¸å­˜åœ¨"}), 404

    # æ£€æŸ¥å¯¹åº”çš„.rawæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    base_name = os.path.splitext(filename)[0]
    raw_filename = base_name + ".raw"
    raw_path = os.path.join(INFERENCE_UPLOAD_FOLDER, raw_filename)
    if not os.path.exists(raw_path):
        return jsonify({"error": f"å¯¹åº”çš„RAWæ–‡ä»¶ä¸å­˜åœ¨: {raw_filename}"}), 404

    # é‡ç½®æ¨ç†çŠ¶æ€
    inference_status.update(
        {
            "is_running": True,
            "progress": 0,
            "current_step": "åˆå§‹åŒ–æ¨ç†...",
            "result_image": None,
            "error": None,
            "start_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "end_time": None,
        }
    )

    def run_inference_thread():
        try:
            add_server_log(f"å¼€å§‹æ¨ç†: {filename}")
            inference_status["current_step"] = "åŠ è½½æ¨¡å‹..."
            inference_status["progress"] = 10

            # å¯¼å…¥æ¨ç†å‡½æ•°
            if use_federated:
                from federated_inference_utils import (
                    predict_with_federated_model,
                    visualize_federated_results,
                )

                inference_status["current_step"] = "ä½¿ç”¨è”é‚¦æ¨¡å‹è¿›è¡Œé¢„æµ‹..."
                inference_status["progress"] = 30

                # è¿è¡Œæ¨ç†ï¼Œæ”¯æŒå¿«é€Ÿæ¨¡å¼
                nodules, prob_map, image, spacing, origin = (
                    predict_with_federated_model(file_path, fast_mode=fast_mode)
                )

                inference_status["current_step"] = "ç”Ÿæˆå¯è§†åŒ–ç»“æœ..."
                inference_status["progress"] = 70

                # ç”Ÿæˆç»“æœå›¾åƒå¹¶ä¿å­˜ä¸ºbase64
                result_path = visualize_federated_results(
                    image, prob_map, nodules, spacing, origin, save_path=True
                )

            else:
                from show_nodules import show_predicted_nodules

                inference_status["current_step"] = "ä½¿ç”¨å¿«é€Ÿæ¨¡å¼è¿›è¡Œé¢„æµ‹..."
                inference_status["progress"] = 50

                result_path = show_predicted_nodules(
                    file_path, confidence_threshold=0.3, save_result=True
                )

            # è¯»å–ç»“æœå›¾åƒå¹¶è½¬æ¢ä¸ºbase64
            if result_path and os.path.exists(result_path):
                with open(result_path, "rb") as img_file:
                    img_data = img_file.read()
                    base64_image = base64.b64encode(img_data).decode("utf-8")
                    inference_status["result_image"] = (
                        f"data:image/png;base64,{base64_image}"
                    )

            inference_status["current_step"] = "æ¨ç†å®Œæˆ"
            inference_status["progress"] = 100
            inference_status["is_running"] = False
            inference_status["end_time"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            add_server_log(f"æ¨ç†å®Œæˆ: {filename}")

        except Exception as e:
            inference_status.update(
                {
                    "is_running": False,
                    "error": str(e),
                    "end_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                }
            )
            add_server_log(f"æ¨ç†å¤±è´¥: {str(e)}")

    # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œæ¨ç†
    inference_thread = threading.Thread(target=run_inference_thread)
    inference_thread.daemon = True
    inference_thread.start()

    return jsonify({"message": "æ¨ç†å·²å¯åŠ¨"})


@app.route("/api/server/get_inference_status", methods=["GET"])
def get_inference_status():
    """è·å–æ¨ç†çŠ¶æ€"""
    if "username" not in session or session["role"] != "server":
        return jsonify({"error": "æœªæˆæƒ"}), 403

    return jsonify(inference_status)


@app.route("/api/server/get_inference_result", methods=["GET"])
def get_inference_result():
    """è·å–æ¨ç†ç»“æœå›¾åƒ"""
    if "username" not in session or session["role"] != "server":
        return jsonify({"error": "æœªæˆæƒ"}), 403

    if inference_status["result_image"]:
        return jsonify({"result_image": inference_status["result_image"]})
    else:
        return jsonify({"error": "æš‚æ— ç»“æœå›¾åƒ"}), 404


@app.route("/api/server/delete_inference_file", methods=["DELETE"])
def delete_inference_file():
    """åˆ é™¤æ¨ç†æ–‡ä»¶"""
    if "username" not in session or session["role"] != "server":
        return jsonify({"error": "æœªæˆæƒ"}), 403

    data = request.get_json()
    filename = data.get("filename")

    if not filename:
        return jsonify({"error": "æœªæŒ‡å®šæ–‡ä»¶å"}), 400

    # åˆ é™¤.mhdæ–‡ä»¶
    mhd_path = os.path.join(INFERENCE_UPLOAD_FOLDER, filename)

    # è·å–å¯¹åº”çš„.rawæ–‡ä»¶å
    base_name = os.path.splitext(filename)[0]
    raw_filename = base_name + ".raw"
    raw_path = os.path.join(INFERENCE_UPLOAD_FOLDER, raw_filename)

    deleted_files = []
    errors = []

    # åˆ é™¤.mhdæ–‡ä»¶
    if os.path.exists(mhd_path):
        try:
            os.remove(mhd_path)
            deleted_files.append(filename)
            add_server_log(f"å·²åˆ é™¤æ¨ç†æ–‡ä»¶: {filename}")
        except Exception as e:
            errors.append(f"åˆ é™¤{filename}å¤±è´¥: {str(e)}")

    # åˆ é™¤å¯¹åº”çš„.rawæ–‡ä»¶
    if os.path.exists(raw_path):
        try:
            os.remove(raw_path)
            deleted_files.append(raw_filename)
            add_server_log(f"å·²åˆ é™¤æ¨ç†æ–‡ä»¶: {raw_filename}")
        except Exception as e:
            errors.append(f"åˆ é™¤{raw_filename}å¤±è´¥: {str(e)}")

    if not deleted_files:
        return jsonify({"error": "æ–‡ä»¶ä¸å­˜åœ¨"}), 404

    # ä»ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨ä¸­ç§»é™¤
    inference_status["uploaded_files"] = [
        f
        for f in inference_status["uploaded_files"]
        if f["name"] not in [filename, raw_filename]
    ]

    response_message = f"å·²åˆ é™¤æ–‡ä»¶: {', '.join(deleted_files)}"
    if errors:
        response_message += f" (éƒ¨åˆ†é”™è¯¯: {', '.join(errors)})"

    return jsonify({"message": response_message, "deleted_files": deleted_files})


# ============================
# å®¢æˆ·ç«¯æ¨ç†ç›¸å…³APIç«¯ç‚¹
# ============================


@app.route("/api/client/upload_inference_file", methods=["POST"])
def client_upload_inference_file():
    """å®¢æˆ·ç«¯ä¸Šä¼ æ¨ç†æ–‡ä»¶ï¼ˆæ”¯æŒå¤šæ–‡ä»¶ä¸Šä¼ ï¼‰"""
    if "username" not in session or session["role"] != "client":
        return jsonify({"error": "æœªæˆæƒ"}), 403

    username = session["username"]
    files = request.files.getlist("files")
    if not files or len(files) == 0:
        return jsonify({"error": "æœªé€‰æ‹©æ–‡ä»¶"}), 400

    # ä¸ºæ¯ä¸ªå®¢æˆ·ç«¯åˆ›å»ºç‹¬ç«‹çš„æ¨ç†æ–‡ä»¶å¤¹
    client_inference_folder = os.path.join(
        CLIENT_INFERENCE_UPLOAD_FOLDER, f"{username}_inference"
    )
    if not os.path.exists(client_inference_folder):
        os.makedirs(client_inference_folder)

    uploaded_files = []
    errors = []

    # éªŒè¯æ–‡ä»¶ç±»å‹å’Œé…å¯¹
    mhd_files = []
    raw_files = []

    for file in files:
        if file.filename == "":
            continue

        if file.filename.lower().endswith(".mhd"):
            mhd_files.append(file)
        elif file.filename.lower().endswith(".raw"):
            raw_files.append(file)
        else:
            errors.append(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file.filename}")

    if not mhd_files:
        return jsonify({"error": "å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ª.mhdæ–‡ä»¶"}), 400

    # éªŒè¯æ¯ä¸ª.mhdæ–‡ä»¶éƒ½æœ‰å¯¹åº”çš„.rawæ–‡ä»¶
    for mhd_file in mhd_files:
        base_name = os.path.splitext(mhd_file.filename)[0]
        raw_filename = base_name + ".raw"

        # æŸ¥æ‰¾å¯¹åº”çš„.rawæ–‡ä»¶
        corresponding_raw = None
        for raw_file in raw_files:
            if raw_file.filename == raw_filename:
                corresponding_raw = raw_file
                break

        if not corresponding_raw:
            errors.append(f"ç¼ºå°‘å¯¹åº”çš„.rawæ–‡ä»¶: {raw_filename}")
            continue

        # ä¸Šä¼ æ–‡ä»¶å¯¹
        try:
            # å¤„ç†æ–‡ä»¶åå†²çª
            mhd_filename = mhd_file.filename
            raw_filename = corresponding_raw.filename

            counter = 1
            base_name = os.path.splitext(mhd_filename)[0]

            while os.path.exists(
                os.path.join(client_inference_folder, mhd_filename)
            ) or os.path.exists(os.path.join(client_inference_folder, raw_filename)):
                mhd_filename = f"{base_name}_{counter}.mhd"
                raw_filename = f"{base_name}_{counter}.raw"
                counter += 1

            # ä¿å­˜.mhdæ–‡ä»¶
            mhd_path = os.path.join(client_inference_folder, mhd_filename)
            mhd_file.save(mhd_path)

            # ä¿å­˜.rawæ–‡ä»¶
            raw_path = os.path.join(client_inference_folder, raw_filename)
            corresponding_raw.save(raw_path)

            # åªå°†.mhdæ–‡ä»¶æ·»åŠ åˆ°çŠ¶æ€ä¸­ï¼ˆæ¨ç†æ—¶ä½¿ç”¨ï¼‰
            client_inference_status["uploaded_files"].append(
                {
                    "name": mhd_filename,
                    "path": mhd_path,
                    "raw_file": raw_filename,
                    "upload_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                }
            )

            uploaded_files.extend([mhd_filename, raw_filename])
            add_server_log(
                f"å®¢æˆ·ç«¯ {username} æ¨ç†æ–‡ä»¶å¯¹ä¸Šä¼ æˆåŠŸ: {mhd_filename}, {raw_filename}"
            )

        except Exception as e:
            errors.append(f"ä¸Šä¼ æ–‡ä»¶å¯¹å¤±è´¥ {mhd_file.filename}: {str(e)}")

    if not uploaded_files and errors:
        return jsonify({"error": f"ä¸Šä¼ å¤±è´¥: {'; '.join(errors)}"}), 500

    response_message = f"æˆåŠŸä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶"
    if errors:
        response_message += f" (éƒ¨åˆ†é”™è¯¯: {'; '.join(errors)})"

    return jsonify(
        {
            "message": response_message,
            "uploaded_files": uploaded_files,
            "errors": errors,
        }
    )


@app.route("/api/client/list_inference_files", methods=["GET"])
def client_list_inference_files():
    """è·å–å®¢æˆ·ç«¯å·²ä¸Šä¼ çš„æ¨ç†æ–‡ä»¶åˆ—è¡¨"""
    if "username" not in session or session["role"] != "client":
        return jsonify({"error": "æœªæˆæƒ"}), 403

    username = session["username"]
    client_inference_folder = os.path.join(
        CLIENT_INFERENCE_UPLOAD_FOLDER, f"{username}_inference"
    )

    files = []
    if os.path.exists(client_inference_folder):
        for filename in os.listdir(client_inference_folder):
            if filename.lower().endswith(".mhd"):
                file_path = os.path.join(client_inference_folder, filename)
                stat = os.stat(file_path)

                # æ£€æŸ¥å¯¹åº”çš„.rawæ–‡ä»¶æ˜¯å¦å­˜åœ¨
                base_name = os.path.splitext(filename)[0]
                raw_filename = base_name + ".raw"
                raw_path = os.path.join(client_inference_folder, raw_filename)
                has_raw_file = os.path.exists(raw_path)

                raw_size = 0
                if has_raw_file:
                    raw_stat = os.stat(raw_path)
                    raw_size = raw_stat.st_size

                files.append(
                    {
                        "name": filename,
                        "path": file_path,
                        "size": stat.st_size,
                        "raw_file": raw_filename if has_raw_file else None,
                        "raw_size": raw_size,
                        "total_size": stat.st_size + raw_size,
                        "has_pair": has_raw_file,
                        "upload_time": datetime.fromtimestamp(stat.st_mtime).strftime(
                            "%Y-%m-%d %H:%M:%S"
                        ),
                    }
                )

    return jsonify({"files": files})


@app.route("/api/client/run_inference", methods=["POST"])
def client_run_inference_api():
    """å®¢æˆ·ç«¯è¿è¡Œæ¨ç†"""
    if "username" not in session or session["role"] != "client":
        return jsonify({"error": "æœªæˆæƒ"}), 403

    if client_inference_status["is_running"]:
        return jsonify({"error": "æ¨ç†æ­£åœ¨è¿è¡Œä¸­"}), 400

    username = session["username"]
    data = request.get_json()
    filename = data.get("filename")
    use_federated = data.get("use_federated", True)
    fast_mode = data.get("fast_mode", False)

    if not filename:
        return jsonify({"error": "æœªæŒ‡å®šæ–‡ä»¶å"}), 400

    client_inference_folder = os.path.join(
        CLIENT_INFERENCE_UPLOAD_FOLDER, f"{username}_inference"
    )
    file_path = os.path.join(client_inference_folder, filename)
    if not os.path.exists(file_path):
        return jsonify({"error": "MHDæ–‡ä»¶ä¸å­˜åœ¨"}), 404

    # æ£€æŸ¥å¯¹åº”çš„.rawæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    base_name = os.path.splitext(filename)[0]
    raw_filename = base_name + ".raw"
    raw_path = os.path.join(client_inference_folder, raw_filename)
    if not os.path.exists(raw_path):
        return jsonify({"error": f"å¯¹åº”çš„RAWæ–‡ä»¶ä¸å­˜åœ¨: {raw_filename}"}), 404

    # é‡ç½®å®¢æˆ·ç«¯æ¨ç†çŠ¶æ€
    client_inference_status.update(
        {
            "is_running": True,
            "progress": 0,
            "current_step": "åˆå§‹åŒ–æ¨ç†...",
            "result_image": None,
            "error": None,
            "start_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "end_time": None,
        }
    )

    def run_client_inference_thread():
        try:
            add_server_log(f"å®¢æˆ·ç«¯ {username} å¼€å§‹æ¨ç†: {filename}")
            client_inference_status["current_step"] = "åŠ è½½æ¨¡å‹..."
            client_inference_status["progress"] = 10

            # å¯¼å…¥æ¨ç†å‡½æ•°
            if use_federated:
                from federated_inference_utils import (
                    predict_with_federated_model,
                    visualize_federated_results,
                )

                client_inference_status["current_step"] = "ä½¿ç”¨è”é‚¦æ¨¡å‹è¿›è¡Œé¢„æµ‹..."
                client_inference_status["progress"] = 30

                # è¿è¡Œæ¨ç†ï¼Œæ”¯æŒå¿«é€Ÿæ¨¡å¼
                nodules, prob_map, image, spacing, origin = (
                    predict_with_federated_model(file_path, fast_mode=fast_mode)
                )

                client_inference_status["current_step"] = "ç”Ÿæˆå¯è§†åŒ–ç»“æœ..."
                client_inference_status["progress"] = 70

                # ç”Ÿæˆç»“æœå›¾åƒå¹¶ä¿å­˜ä¸ºbase64
                result_path = visualize_federated_results(
                    image, prob_map, nodules, spacing, origin, save_path=True
                )

            else:
                from show_nodules import show_predicted_nodules

                client_inference_status["current_step"] = "ä½¿ç”¨å¿«é€Ÿæ¨¡å¼è¿›è¡Œé¢„æµ‹..."
                client_inference_status["progress"] = 50

                result_path = show_predicted_nodules(
                    file_path, confidence_threshold=0.3, save_result=True
                )

            # è¯»å–ç»“æœå›¾åƒå¹¶è½¬æ¢ä¸ºbase64
            if result_path and os.path.exists(result_path):
                with open(result_path, "rb") as img_file:
                    img_data = img_file.read()
                    base64_image = base64.b64encode(img_data).decode("utf-8")
                    client_inference_status["result_image"] = (
                        f"data:image/png;base64,{base64_image}"
                    )

            client_inference_status["current_step"] = "æ¨ç†å®Œæˆ"
            client_inference_status["progress"] = 100
            client_inference_status["is_running"] = False
            client_inference_status["end_time"] = datetime.now().strftime(
                "%Y-%m-%d %H:%M:%S"
            )

            add_server_log(f"å®¢æˆ·ç«¯ {username} æ¨ç†å®Œæˆ: {filename}")

        except Exception as e:
            client_inference_status.update(
                {
                    "is_running": False,
                    "error": str(e),
                    "end_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                }
            )
            add_server_log(f"å®¢æˆ·ç«¯ {username} æ¨ç†å¤±è´¥: {str(e)}")

    # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œæ¨ç†
    inference_thread = threading.Thread(target=run_client_inference_thread)
    inference_thread.daemon = True
    inference_thread.start()

    return jsonify({"message": "æ¨ç†å·²å¯åŠ¨"})


@app.route("/api/client/get_inference_status", methods=["GET"])
def client_get_inference_status():
    """è·å–å®¢æˆ·ç«¯æ¨ç†çŠ¶æ€"""
    if "username" not in session or session["role"] != "client":
        return jsonify({"error": "æœªæˆæƒ"}), 403

    return jsonify(client_inference_status)


@app.route("/api/client/delete_inference_file", methods=["DELETE"])
def client_delete_inference_file():
    """åˆ é™¤å®¢æˆ·ç«¯æ¨ç†æ–‡ä»¶"""
    if "username" not in session or session["role"] != "client":
        return jsonify({"error": "æœªæˆæƒ"}), 403

    username = session["username"]
    data = request.get_json()
    filename = data.get("filename")

    if not filename:
        return jsonify({"error": "æœªæŒ‡å®šæ–‡ä»¶å"}), 400

    client_inference_folder = os.path.join(
        CLIENT_INFERENCE_UPLOAD_FOLDER, f"{username}_inference"
    )

    # åˆ é™¤.mhdæ–‡ä»¶
    mhd_path = os.path.join(client_inference_folder, filename)

    # è·å–å¯¹åº”çš„.rawæ–‡ä»¶å
    base_name = os.path.splitext(filename)[0]
    raw_filename = base_name + ".raw"
    raw_path = os.path.join(client_inference_folder, raw_filename)

    deleted_files = []
    errors = []

    # åˆ é™¤.mhdæ–‡ä»¶
    if os.path.exists(mhd_path):
        try:
            os.remove(mhd_path)
            deleted_files.append(filename)
            add_server_log(f"å®¢æˆ·ç«¯ {username} å·²åˆ é™¤æ¨ç†æ–‡ä»¶: {filename}")
        except Exception as e:
            errors.append(f"åˆ é™¤{filename}å¤±è´¥: {str(e)}")

    # åˆ é™¤å¯¹åº”çš„.rawæ–‡ä»¶
    if os.path.exists(raw_path):
        try:
            os.remove(raw_path)
            deleted_files.append(raw_filename)
            add_server_log(f"å®¢æˆ·ç«¯ {username} å·²åˆ é™¤æ¨ç†æ–‡ä»¶: {raw_filename}")
        except Exception as e:
            errors.append(f"åˆ é™¤{raw_filename}å¤±è´¥: {str(e)}")

    if not deleted_files:
        return jsonify({"error": "æ–‡ä»¶ä¸å­˜åœ¨"}), 404

    # ä»ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨ä¸­ç§»é™¤
    client_inference_status["uploaded_files"] = [
        f
        for f in client_inference_status["uploaded_files"]
        if f["name"] not in [filename, raw_filename]
    ]

    response_message = f"å·²åˆ é™¤æ–‡ä»¶: {', '.join(deleted_files)}"
    if errors:
        response_message += f" (éƒ¨åˆ†é”™è¯¯: {', '.join(errors)})"

    return jsonify({"message": response_message, "deleted_files": deleted_files})


# åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–å®¢æˆ·ç«¯æ•°æ®çŠ¶æ€
initialize_client_data_status()

if __name__ == "__main__":
    # æ·»åŠ ä¸€äº›åˆå§‹æ—¥å¿—
    add_server_log("æœåŠ¡å™¨å¯åŠ¨")
    add_server_log("ç­‰å¾…å®¢æˆ·ç«¯è¿æ¥å’Œä¸Šä¼ æ•°æ®")

    # ä½¿ç”¨ SocketIO è¿è¡Œåº”ç”¨
    socketio.run(app, port=5000)
